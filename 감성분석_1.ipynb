{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 감성 분석(sentiment analysis)\n","\n","                                                    note by D.H.Yeom\n","                                                    \n","* 감성 분석: 문서에 대해 좋다(positive) 혹은 나쁘다(negative)로 평가"],"metadata":{"id":"pSPtJ9K240Wz"}},{"cell_type":"markdown","source":["#1.라이브러리(Library) & 데이터(Data)"],"metadata":{"id":"Ydb8bE4y5UqO"}},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"id":"pUgqwv42CpIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","print('Found GPU at: {}', format(device_name))"],"metadata":{"id":"T0iTFXzD3-wW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AobNvfHA9Og"},"outputs":[],"source":["import pickle\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import re\n","import urllib.request\n","\n","from konlpy.tag import Okt\n","from tqdm import tqdm\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","source":["* 데이터 로드\n","\n"],"metadata":{"id":"HsUaeHtVCZ_Y"}},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"id":"Lrt35Ch-IikE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = pd.read_table('ratings_train.txt')\n","test_data = pd.read_table('ratings_test.txt')"],"metadata":{"id":"p8KNza1DJPF9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"],"metadata":{"id":"c_qnDfRFCbyQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Drescrition\n","* id, document, label로 구성."],"metadata":{"id":"CpueBbpzDSF4"}},{"cell_type":"code","source":["train_data.info()"],"metadata":{"id":"PxvcGVzrPX96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data.info()"],"metadata":{"id":"wKVIc1QKCbgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('학습용 데이터 리뷰 개수 :',len(train_data))"],"metadata":{"id":"9HeepUo0DCTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습용 데이터 리뷰 개수\n","train_data.shape"],"metadata":{"id":"voqKXLZtNQ2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 상위 5개 출력\n","train_data[:5]"],"metadata":{"id":"re5zs93TDGyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_data의 리뷰 개수 확인\n","print('테스트용 리뷰 개수 :',len(test_data)) # 테스트용 리뷰 개수 출력"],"metadata":{"id":"M0dc0zlUDLgC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data[:5]"],"metadata":{"id":"BRWo2PMkDtyL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#2. 데이터 전처리"],"metadata":{"id":"ATFCrKHTD6qS"}},{"cell_type":"markdown","source":["* # train_data의 데이터 중복 유무 확인"],"metadata":{"id":"BBIPx3EhPp7L"}},{"cell_type":"code","source":["# document 열과 label 열의 중복을 제외한 값의 개수\n","train_data['document'].nunique(), train_data['label'].nunique()"],"metadata":{"id":"orppgOTJDxAJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[결과 해석]**\n","* 총 150,000개의 샘플 가운데 document 중복을 제거한 샘플 개수가 146,182개로 약 4,000개의 중복 샘플이 존재.\n","* label 열은 0 또는 1의 두 가지 값만을 가지므로 '2' 출력."],"metadata":{"id":"kRSx0LvC5hmd"}},{"cell_type":"markdown","source":["* 중복 샘플 제거"],"metadata":{"id":"sVTeEGgfQR8T"}},{"cell_type":"code","source":["# document 열의 중복 제거\n","train_data.drop_duplicates(subset=['document'], inplace=True)"],"metadata":{"id":"KsM_kXUmBBFA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#중복제거 확인\n","print('샘플수  :',len(train_data))"],"metadata":{"id":"4njrwdCKEbpr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* train_data에서 해당 리뷰의 긍, 부정 유무가 기재되어있는 레이블(label) 값의 분포 확인."],"metadata":{"id":"CmefUEVI5xY-"}},{"cell_type":"code","source":["train_data['label'].value_counts().plot(kind = 'bar')"],"metadata":{"id":"BCWnbUx7BC7c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 샘플의 개수 확인"],"metadata":{"id":"pkXapyM6Ewvj"}},{"cell_type":"code","source":["print(train_data.groupby('label').size().reset_index(name = 'count'))"],"metadata":{"id":"QAOGShl4EtOJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[결과확인]**\n","* 레이블이 0인 리뷰가 근소하게 많음."],"metadata":{"id":"iqcAafgeE4Rp"}},{"cell_type":"markdown","source":["### 리뷰 중에 Null 값을 가진 샘플 여부 확인"],"metadata":{"id":"kbgqJthjRLEo"}},{"cell_type":"code","source":["print(train_data.isnull().values.any())"],"metadata":{"id":"wjOFYK1btrvW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[결과확인]**\n","* True : 데이터 중에 Null 이 존재함.\n","* 어떤 열에 존재하는지 확인."],"metadata":{"id":"jSM9XjnlE_7U"}},{"cell_type":"code","source":["train_data.loc[train_data.document.isnull()]"],"metadata":{"id":"Z1p2VInUFA2a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Null 값을 가진 샘플 제거"],"metadata":{"id":"mM6mllYvFQ-U"}},{"cell_type":"code","source":["train_data = train_data.dropna(how = 'any')    # Null 값이 존재하는 행 제거\n","print(train_data.isnull().values.any())        # Null 값이 존재하는지 확인"],"metadata":{"id":"xKWAKvYUFSu5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Null 샘플이 제거, 제거여부 확인"],"metadata":{"id":"-FrUvYj9FaFw"}},{"cell_type":"code","source":["print(len(train_data))"],"metadata":{"id":"pc_L00A3FbA8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 정규분포식 적용"],"metadata":{"id":"OIpwZ9nJFiLC"}},{"cell_type":"markdown","source":["**[한글에 적용]**\n","* 먼저 자음과 모음에 대한 범위 지정.\n","* 일반적으로 자음의 범위는 ㄱ ~ ㅎ, 모음의 범위는 ㅏ ~ ㅣ와 같이 지정 가능\n","* 해당 범위 내의 자음과 모음은  아래의 링크 참조.\n","* 링크 : https://www.unicode.org/charts/PDF/U3130.pdf\n","ㄱ ~ ㅎ: 3131 ~ 314E\n","ㅏ ~ ㅣ: 314F ~ 3163\n","* 완성형 한글의 범위는 가 ~ 힣과 같이 사용\n","* 해당 범위 내에 포함된 음절들은 아래의 링크에서 확인\n","* 링크 : https://www.unicode.org/charts/PDF/UAC00.pdf"],"metadata":{"id":"qHgIc3gMUpK4"}},{"cell_type":"markdown","source":["**[영어 예시]**\n","* 알파벳들을 나타내는 정규 표현식은 [a-zA-Z].\n","* 영어의 소문자와 대문자들을 모두 포함하고 있는 정규 표현식으로, 영어에 속하지 않는 구두점이나 특수문자를 제거할 수 있음."],"metadata":{"id":"_SRAajulSwS4"}},{"cell_type":"code","source":["# 알파벳과 공백을 제외하고 모두 제거\n","eng_text = 'Do you really think so? Well, I think we need to talk about it... people~ to~ read~ the FAQ, etc. and actually accept hard~! atheism?@@'\n","print(re.sub(r'[^a-zA-Z ]', '', eng_text))"],"metadata":{"id":"50SP3jSXFdXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data[:5]"],"metadata":{"id":"WDVx3s-H2qg0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* train_data 한글만 남기고 제거."],"metadata":{"id":"A1Yhq7t2Fr6g"}},{"cell_type":"code","source":["# 한글과 공백을 제외하고 모두 제거\n","train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n","train_data[:5]"],"metadata":{"id":"X4RuLnizFmON"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[정리]**\n","* 기존의 공백(띄어쓰기)은 유지되면서 구두점 등은 제거\n","* 영화 리뷰는 한글이 아니더라도 영어, 숫자, 특수문자로도 리뷰를 업로드할 수 있음. 즉, 기존에 한글이 없는 리뷰였다면 아무런 값이 없는 빈(empty) 값이 되었을 것임.\n","* train_data에 공백(whitespace)만 있거나 빈 값을 가진 행이 있다면 Null 값으로 변경하도록 하고, Null 값이 존재하는지 확인 필요."],"metadata":{"id":"i7I7EVxDF2Jg"}},{"cell_type":"code","source":["train_data['document'] = train_data['document'].str.replace('^ +', \"\")      # white space 데이터를 빈값(empty value)로 변경\n","train_data['document'].replace('', np.nan, inplace=True)\n","print(train_data.isnull().sum())"],"metadata":{"id":"dsX6op_lFV0W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[결과확인]**\n","* Null 값이 789개 확인됨."],"metadata":{"id":"wDvVuLeTF-ND"}},{"cell_type":"code","source":["# Null 값의 행 출력\n","train_data.loc[train_data.document.isnull()][:5]"],"metadata":{"id":"3Ml62O83FMdf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Null 샘플은 리뷰가 없으믈로 긍,부정 데이터에 의미가 없음\n","* 따라서 데이터를 제거해야 함"],"metadata":{"id":"kD3EoIjoGE7R"}},{"cell_type":"code","source":["train_data = train_data.dropna(how = 'any')\n","print(len(train_data))"],"metadata":{"id":"_SPfprqlFC_-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 테스트 데이터도 동일하게 전처리 과정 수행"],"metadata":{"id":"R5umf4ivGQOH"}},{"cell_type":"code","source":["test_data.drop_duplicates(subset = ['document'], inplace=True)                      # document 열에서 중복인 내용이 있다면 중복 제거\n","test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n","test_data['document'] = test_data['document'].str.replace('^ +', \"\")                # 공백은 empty 값으로 변경\n","test_data['document'].replace('', np.nan, inplace=True)                             # 공백은 Null 값으로 변경\n","test_data = test_data.dropna(how='any') # Null 값 제거\n","print('샘플의 개수 :',len(test_data))"],"metadata":{"id":"ZrveoUVLE8C3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#3. 토큰화\n","* 불용어 제거: 불용어는 한국어의 조사, 접속사 등의 보편적인 불용어를 사용할 수도 있으나, 데이터를 지속적으로 검토하면서 추가하는 경우도 많음."],"metadata":{"id":"KCXI3XhVGcOD"}},{"cell_type":"code","source":["stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"],"metadata":{"id":"6iToTCidteEg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[형태소 분석기 적용]**\n","* 형태소 분석기는 KoNLPy의 Okt 사용"],"metadata":{"id":"C6xss7Fs5-CA"}},{"cell_type":"code","source":["# 예시\n","okt = Okt()\n","okt.morphs('와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔. 흥행 실패는 따논 당상이군', stem = True)"],"metadata":{"id":"C2APFKILthR3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* stem = True를 사용하면 일정 수준의 정규화를 수행해 줌.\n","* '이런'이 '이렇다'로, '만드는'이 '만들다'로 변환."],"metadata":{"id":"pgvIwiLTG5OL"}},{"cell_type":"markdown","source":["* train_data에 형태소 분석기를 사용하여 토큰화를 하면서 불용어 제거.\n","* 결과를 X_train에 저장."],"metadata":{"id":"8SrnkSdyYt5K"}},{"cell_type":"code","source":["X_train = []\n","for sentence in tqdm(train_data['document']):\n","    tokenized_sentence = okt.morphs(sentence, stem=True)                                            # 토큰화\n","    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords]     # 불용어 제거\n","    X_train.append(stopwords_removed_sentence)"],"metadata":{"id":"FMnkeShOG8WI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 결과 확인\n","print(X_train[:3])"],"metadata":{"id":"iXkSfR8BG-uA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 테스트 데이터에 대해서도 동일하게 토큰화 실행"],"metadata":{"id":"lWWs7HumHLm6"}},{"cell_type":"code","source":["X_test = []\n","for sentence in tqdm(test_data['document']):\n","    tokenized_sentence = okt.morphs(sentence, stem=True)                                        # 토큰화\n","    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n","    X_test.append(stopwords_removed_sentence)"],"metadata":{"id":"i2Zjrrd8G2jS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#4. 정수 인코딩\n","* 텍스트를 숫자로 처리할 수 있도록 학습 데이터와 테스트 데이터에 정수 인코딩 수행.\n","* 먼저 학습 데이터에 대해 단어 집합(vocaburary)을 만든다."],"metadata":{"id":"h1UOpO7H03C9"}},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train)"],"metadata":{"id":"ok83Xo9Dt44N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 단어 집합이 생성되고, 동시에 각 단어에 고유한 정수가 부여되었음\n","* tokenizer.word_index를 출력하여 확인 가능."],"metadata":{"id":"5fKUebnrHdih"}},{"cell_type":"code","source":["print(tokenizer.word_index)"],"metadata":{"id":"8eFvgi76HhES"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 높은 정수가 부여된 단어들은 등장 빈도수가 매우 낮다\n","* 빈도수가 낮은 단어들은 제거.\n","* 빈도수가 3회 미만인 단어의 비중 확인."],"metadata":{"id":"cUYKmRMRHl_9"}},{"cell_type":"code","source":["threshold = 3\n","total_cnt = len(tokenizer.word_index)        # 단어의 수\n","rare_cnt = 0                                 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0                               # 훈련 데이터의 전체 단어 빈도수 총 합\n","rare_freq = 0                                # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n","\n","# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n","for key, value in tokenizer.word_counts.items():\n","    total_freq = total_freq + value\n","\n","    # 단어의 등장 빈도수가 threshold보다 작으면\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value\n","\n","print('단어 집합(vocabulary)의 크기 :',total_cnt)\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n","print(\"희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"],"metadata":{"id":"2RW2Dl86Hnga"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 등장 빈도가 threshold 값인 3회 미만은 단어 집합에서 절반 이상\n","* 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 1.87%\n","* 등장 빈도가 2회 이하인 단어들은 자연어 처리에서 별로 중요하지 않음\n","* 이 단어들은 정수 인코딩 과정에서 배제."],"metadata":{"id":"J_QpNcZFHwNd"}},{"cell_type":"code","source":["# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n","# 0번 패딩 토큰을 고려하여 + 1\n","vocab_size = total_cnt - rare_cnt + 1\n","print('단어 집합의 크기 :',vocab_size)"],"metadata":{"id":"WfF_XUh6t73D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 단어 집합의 크기는 19,416개\n","* 이를 케라스 토크나이저의 인자로 넘겨주고 텍스트 시퀀스를 정수 시퀀스로 변환."],"metadata":{"id":"8YUuvNMHIvMz"}},{"cell_type":"code","source":["tokenizer = Tokenizer(vocab_size)\n","tokenizer.fit_on_texts(X_train)\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)"],"metadata":{"id":"zP5PPhtzIwME"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 정수 인코딩 진행 확인: X_train에 대해서 상위 3개의 샘플 출력"],"metadata":{"id":"v_lwxySaIyqs"}},{"cell_type":"code","source":["print(X_train[:3])"],"metadata":{"id":"cx5rY0omI0vY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[정리]**\n","* 각 샘플 내의 단어들은 각 단어에 대한 정수로 변환된 것을 확인\n","* 단어의 개수는 19,416개로 제한되었으므로 0번 단어 ~ 19,415번 단어까지만 사용\n","* 0번 단어는 패딩을 위한 토큰임에 주의.\n","* train_data에서 y_train과 y_test를 별도로 저장."],"metadata":{"id":"XTFkwAOdI3dT"}},{"cell_type":"code","source":["y_train = np.array(train_data['label'])\n","y_test = np.array(test_data['label'])"],"metadata":{"id":"Q5zrQCSuI68I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[빈 샘플(empty samples)]제거**\n","* 전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 빈(empty) 샘플이 되었다는 것을 의미\n","* 빈 샘플들은 어떤 레이블이든 의미가 없으므로 빈 샘플들을 제거해야 함\n","* 각 샘플들의 길이를 확인해서 길이가 0인 샘플들의 인덱스를 확인."],"metadata":{"id":"b5V1qJTlI_X7"}},{"cell_type":"code","source":["drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"],"metadata":{"id":"30aZtGWSJB0v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[정리]**\n","* drop_train에는 X_train으로부터 얻은 빈 샘플들의 인덱스가 저장됨.\n","* 앞서 학습 데이터(X_train, y_train)의 샘플 개수는 145,791개임을 확인\n","* 빈 샘플들을 제거한 후의 샘플 개수 확인 필요"],"metadata":{"id":"JLeBZVVpJNPF"}},{"cell_type":"code","source":["# 빈 샘플 제거\n","X_train = np.delete(X_train, drop_train, axis=0)\n","y_train = np.delete(y_train, drop_train, axis=0)\n","print(len(X_train))\n","print(len(y_train))"],"metadata":{"id":"0GOvlJQLJJiq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[정리]**\n","* 145,162개로 샘플의 수가 줄어든 것을 확인"],"metadata":{"id":"ciGjGGcBJT9N"}},{"cell_type":"markdown","source":["**[패딩 실행]**\n","* 서로 다른 길이의 샘플들의 길이를 동일하게 맞춰주는 작업\n","* 전체 데이터에서 가장 길이가 긴 리뷰와 전체 데이터의 길이 분포 확인"],"metadata":{"id":"6_esCpf0JXAk"}},{"cell_type":"code","source":["print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n","print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n","plt.hist([len(review) for review in X_train], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"metadata":{"id":"Kvj9Kz5NJJfX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 가장 긴 리뷰의 길이는 69\n","* 그래프를 봤을 때 전체 데이터의 길이 분포는 대체적으로 약 11내외\n","* 모델이 처리할 수 있도록 X_train과 X_test의 모든 샘플의 길이를 특정 길이로 동일하게 맞춰줄 필요가 있음\n","* 특정 길이 변수를 max_len으로 정함.\n","* 대부분의 리뷰가 내용이 잘리지 않도록 할 수 있는 최적의 max_len의 값 확인\n","* 전체 샘플 중 길이가 max_len 이하인 샘플의 비율이 몇 %인지 확인하는 함수를 만듬."],"metadata":{"id":"EI2NCteeJa-W"}},{"cell_type":"code","source":["def below_threshold_len(max_len, nested_list):\n","  count = 0\n","  for sentence in nested_list:\n","    if(len(sentence) <= max_len):\n","        count = count + 1\n","  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"],"metadata":{"id":"HMKYfHkhJfCP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 위의 분포 그래프에서, max_len = 30이 적당할 것으로 판단.\n","* 이 값이 얼마나 많은 리뷰 길이를 커버하는지 확인"],"metadata":{"id":"B6eftiLUJjVe"}},{"cell_type":"code","source":["max_len = 30\n","below_threshold_len(max_len, X_train)"],"metadata":{"id":"7wxLjmH3Jm54"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 전체 훈련 데이터 중 약 94%의 리뷰가 30이하의 길이를 가지는 것을 확인\n","* 따라서, 모든 샘플의 길이를 30으로 맞춤."],"metadata":{"id":"R-ThuwfXJsKc"}},{"cell_type":"markdown","source":["#-------\n","##굿럭!!!"],"metadata":{"id":"UReRxyaQiSYq"}},{"cell_type":"markdown","source":["* codecs 패키지: 유니코드로 인코딩하며 읽기 위해\n","* 읽어들인 결과는 유니코드 문자열"],"metadata":{"id":"lhjMD_IeX9Do"}},{"cell_type":"code","source":["import codecs\n","with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n","    data = [line.split('\\t') for line in f.read().splitlines()]\n","    data = data[1:]                             # header 제외"],"metadata":{"id":"NzFRSXC-XFQy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 데이터가 id, 내용, 평점으로 구성.내용을 X, 평점을 y로 저장.\n","* zip(*시퀀스데이터) 함수는 시퀀스형 데이터 타입을 인수로 하여 각 element들이 순서에 맞게 쌍으로 생로운 zip이라는 데이터 타입 object를 생성하는 내장함수이다.\n","* zip()된 결과를 다시 원래의 시퀀스데이터로 만들고자 할때 zip(*시퀀스데이터)을 하여 unpacking함."],"metadata":{"id":"NP-C3BtQYSCK"}},{"cell_type":"code","source":["X = list(zip(*data))[1]\n","y = np.array(list(zip(*data))[2], dtype=int)"],"metadata":{"id":"oKEryJQ8XFNb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" * 다항 나이브 베이즈 모형으로 학습"],"metadata":{"id":"m0NUWRQ4bJQZ"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer #각 문서에 어떤 단어가 몇 번 등장했는지를 파악할 때 사용합니다. 단어를 세서(count) 문서를 벡터화(vectorize)한다는 의미입니다\n","from sklearn.naive_bayes import MultinomialNB    #naive bayes 분류기, 클래스별로 특성의 평균을 계산. 카운트 데이터(ex 문장에 나타난 단어의 횟수)에 적용가능\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report  #분류 모델의 평가 지표를 출력해주는 함수\n","\n","model1 = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('mb', MultinomialNB()),\n","])"],"metadata":{"id":"p8xtBXiRioD6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 모형의 성능 확인을 위해 테스트 데이터 로드"],"metadata":{"id":"gwYZFN_8ewS3"}},{"cell_type":"code","source":["%%time\n","model1.fit(X, y)"],"metadata":{"id":"wii1G5P4VXuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import codecs\n","with codecs.open(\"ratings_test.txt\", encoding='utf-8') as f:\n","    data_test = [line.split('\\t') for line in f.read().splitlines()]\n","    data_test = data_test[1:]   # header 제외"],"metadata":{"id":"4A8RacvgWK8F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test = list(zip(*data_test))[1]\n","y_test = np.array(list(zip(*data_test))[2], dtype=int)\n","\n","print(classification_report(y_test, model1.predict(X_test)))"],"metadata":{"id":"cOjJlyqpekwG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 분류 모델의 평가 지표: 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-score.\n","* Precision(정밀도): 예측한 클래스 중 실제로 해당 클래스인 데이터의 비율.\n","* Recall(재현율): 실제 클래스 중 예측한 클래스와 일치한 데이터의 비율.\n","* F1-score: Precision과 Recall의 조화평균.\n","* Support: 각 클래스의 실제 데이터 수."],"metadata":{"id":"iRkJWmq0d8iB"}},{"cell_type":"markdown","source":["* Tfidf 방법을 사용한 결과와 비교"],"metadata":{"id":"W6VgReT6e3Pl"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","model2 = Pipeline([\n","    ('vect', TfidfVectorizer()),\n","    ('mb', MultinomialNB()),\n","])"],"metadata":{"id":"SSQw5NeRekpv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","model2.fit(X, y)"],"metadata":{"id":"gvzu3aIJfHIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, model2.predict(X_test)))"],"metadata":{"id":"lUO5-jrFfKDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 형태소 분석기를 사용한 결과와 비"],"metadata":{"id":"VD80MZIqfRVy"}},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"id":"x87HQGipfN9V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","pos_tagger = Okt()\n","\n","def tokenize_pos(doc):\n","    return ['/'.join(t) for t in pos_tagger.pos(doc)]"],"metadata":{"id":"3ggwWJznfY77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model3 = Pipeline([\n","    ('vect', CountVectorizer(tokenizer=tokenize_pos)),\n","    ('mb', MultinomialNB()),\n","])"],"metadata":{"id":"GZBtCyP8fb4s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","model3.fit(X, y)"],"metadata":{"id":"lnBNLvyife3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, model3.predict(X_test)))"],"metadata":{"id":"l8Oat6LUflZ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* gram 을 사용하여 성능 개선\n","- N-gram은 문자열에서 N개의 연속된 요소를 추출하는 방법."],"metadata":{"id":"FW4CMfQagDGQ"}},{"cell_type":"code","source":["model4 = Pipeline([\n","    ('vect', TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1, 2))),\n","    ('mb', MultinomialNB()),\n","])"],"metadata":{"id":"54hUXsiBeIV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","model4.fit(X, y)"],"metadata":{"id":"BXjzZzVEgOnG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_test, model4.predict(X_test)))"],"metadata":{"id":"vGJhM3ijgTuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v-VLTh48luCp"},"execution_count":null,"outputs":[]}]}